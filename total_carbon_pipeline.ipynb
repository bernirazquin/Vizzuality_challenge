{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b59dc12d",
   "metadata": {},
   "source": [
    "# Vizzuality Challenge, ETL pipeline. \n",
    " Summarized total ecosystem carbon of the northern lakes region in the USA using data from the National Forest Carbon Monitoring System."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f43834",
   "metadata": {},
   "source": [
    "This Notebook is set to process de downloaded files from the National Forest Carbon Monitoring System (Check Readme.txt for specifications on download.py)\n",
    "\n",
    "This ETL pipeline will: \n",
    "\n",
    "- 1 - Automatically download the necesary data (download.py)\n",
    "\n",
    "- 2 - Select the ROI (Every county of the states of Michigan, Wisconsin and Minnesota) within the USA administrative boundaries Shapefile source\n",
    "\n",
    "- 3 - Summarize Total Ecosystem Carbon for the set ROI. TotalExosystemCarbon_2020 is the choosed raster due that is the \"current\" state of carbon ecosystem data in the region. \n",
    "\n",
    "- 4 - Convert according to necesity CRSs, units, etc. \n",
    "\n",
    "- 5 - Create a .gpkg file with the Total Ecosystem Carbon values\n",
    "\n",
    "- 6 - Upload it to a relational database for inquires \n",
    "\n",
    "- 7 - Simple vizzualization of the output data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b103b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folders are ready: [WindowsPath('d:/Vizzuality_challenge/data/.gitkeep'), WindowsPath('d:/Vizzuality_challenge/data/output'), WindowsPath('d:/Vizzuality_challenge/data/processed'), WindowsPath('d:/Vizzuality_challenge/data/raw')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests, zipfile\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Base directories. Creates the necessary folder structure for simplicity\n",
    "BASE_DIR = Path.cwd()\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "RAW = DATA_DIR / \"raw\"\n",
    "PROCESSED = DATA_DIR / \"processed\"\n",
    "OUTPUT = DATA_DIR / \"output\"\n",
    "\n",
    "for folder in [RAW, PROCESSED, OUTPUT]:\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Folders are ready:\", list(DATA_DIR.glob('*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfe8ded",
   "metadata": {},
   "source": [
    "## Data download\n",
    "Calls to download.py, where downloads the Raster files shared from the National Forest Carbon Monitoring System. \n",
    "The shapefiles are downloaded from Unied States Census bureau (2025). \n",
    "Due to the size of the raster, if the file is once downloaded, it will skip it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f85f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: tl_2025_us_county already exists with content.\n",
      "Skipping: v861gwms9fq68sitl0r3vs2v3moxeu9x already exists with content.\n",
      "âœ… Descargas completas.\n"
     ]
    }
   ],
   "source": [
    "# Data download, quick import from download.py file. You can also execute .py file directly if wanted.\n",
    "# This module is added to the notebook for the intent of traceability. \n",
    "\n",
    "from download import download_and_extract\n",
    "\n",
    "# URLs\n",
    "COUNTIES_URL = \"https://www2.census.gov/geo/tiger/TIGER2025/COUNTY/tl_2025_us_county.zip\"\n",
    "CARBON_URL = \"https://usfs-public.box.com/shared/static/v861gwms9fq68sitl0r3vs2v3moxeu9x.zip\"\n",
    "\n",
    "# Downloads\n",
    "counties_dir = download_and_extract(COUNTIES_URL, RAW)\n",
    "carbon_dir = download_and_extract(CARBON_URL, RAW)\n",
    "\n",
    "# Find paths after download\n",
    "shp_path = list(counties_dir.rglob(\"*.shp\"))[0]\n",
    "raster_path = next(carbon_dir.rglob(\"*.tif\"))\n",
    "print(\"Download completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd59454",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "I prefer working with .gpkg, so will do that. \n",
    "\n",
    "The file identifies each state with a \"FP\" number, Michigan (26), Minnesota (27), Wisconsin (55). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile saved in: d:\\Vizzuality_challenge\\data\\processed\\counties_MI_WI_MN.gpkg\n",
      "County count 242\n"
     ]
    }
   ],
   "source": [
    "# County filtering \n",
    "\n",
    "gdf = gpd.read_file(shp_path)\n",
    "\n",
    "filtered = gdf[gdf[\"STATEFP\"].isin([\"26\", \"27\", \"55\"])].copy()\n",
    "filtered_path = PROCESSED / \"counties_MI_WI_MN.gpkg\" # Change to gpkg for file consistency\n",
    "filtered.to_file(filtered_path, driver=\"GPKG\")\n",
    "\n",
    "print(f\"Shapefile saved in: {filtered_path}\")\n",
    "print(\"County count\", len(filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5befe",
   "metadata": {},
   "source": [
    "Making sure CRSs are correct, .gpkg will reproject to Raster's CRS, we will keep working with this file on zonal stats. \n",
    "\n",
    "As the raster's size is very big, and a raster will not be one output of this pipeline, we will just refer to the original raster's values, \n",
    "\n",
    "avoiding unnecesary raster clip and being more efficient with memory used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07a76f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raster & counties correction\n",
      "Original raster path: d:\\Vizzuality_challenge\\data\\raw\\v861gwms9fq68sitl0r3vs2v3moxeu9x\\Data\\NLS\\NLS_AbovegroundBiomass2020.tif\n",
      "New Geopackage saved in: d:\\Vizzuality_challenge\\data\\processed\\counties_reproj.gpkg\n",
      "âš ï¸ The variable 'clipped_raster' points to the original raster (NLS_AbovegroundBiomass2020.tif) to avoid memory errors.\n"
     ]
    }
   ],
   "source": [
    "# Raster and poligons CRS corrections. Normalization of objects. \n",
    "# Module obtains CRS from raster, equals it to .gpkg file and defines route to be used by Zonal Stats. \n",
    "\n",
    "print(\"\\nRaster & counties correction\")\n",
    "print(\"Original raster path:\", raster_path)\n",
    "\n",
    "with rasterio.open(raster_path) as src:\n",
    "    raster_crs = src.crs\n",
    "    \n",
    "    # 1. Reproyects de .gpkg file to equal rasters CRS. \n",
    "    gdf_reproj = gpd.read_file(filtered_path).to_crs(raster_crs)\n",
    "    \n",
    "    # 2. Saves the reproyected .pgpk for future use\n",
    "    filtered_path_reproj = PROCESSED / \"counties_reproj.gpkg\"\n",
    "    gdf_reproj.to_file(filtered_path_reproj, driver=\"GPKG\")\n",
    "    \n",
    "    clipped_raster = raster_path # Due to RAM limitations...  \n",
    "\n",
    "print(f\"New Geopackage saved in: {filtered_path_reproj}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522efef6",
   "metadata": {},
   "source": [
    "## Zonal stats processing\n",
    "\n",
    "Original raster's units where in Mg COâ‚‚e/acre (a density unit), our interest is to summarize the total carbon in each county, so we will need to convert this\n",
    "\n",
    "units to what we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating total carbon per county...\n",
      " Converting units and running zonal stats...\n",
      "Applying conversion factor (Mg COâ‚‚e/acre to Mg C)...\n",
      "ðŸ§¹ Dropped columns: ['COUNTYNS', 'GEOIDFQ', 'LSAD', 'MTFCC', 'CBSAFP', 'CLASSFP', 'METDIVFP', 'FUNCSTAT', 'ALAND', 'AWATER', 'INTPTLAT', 'INTPTLON']\n",
      "\n",
      "GeoPackage saved in: data\\output\\carbon_total_by_county.gpkg\n",
      "\n",
      "Preview of results:\n",
      "         NAME  raw_sum_CO2e_acre  valid_pixels     total_MgC\n",
      "0    Richland         80253840.0        908127  4.867643e+06\n",
      "1       Grant          4373964.0         67423  2.652944e+05\n",
      "2  Green Lake         18854288.0        275296  1.143571e+06\n",
      "3    Walworth         25412840.0        317963  1.541367e+06\n",
      "4       Eaton         35590720.0        440851  2.158687e+06\n",
      "\n",
      " Process completed successfully. Total counties processed: 242\n"
     ]
    }
   ],
   "source": [
    "# Raster units conversion, Zonal stats, and output export (~ 1min, 30secs)\n",
    "\n",
    "print(\"\\nCalculating total carbon per county...\")\n",
    "\n",
    "# Converts Units in original raster Mg COâ‚‚e/acre to Mg C/pixel. Needed to Sum Total Carbon per county. \n",
    "\n",
    "# FACTOR = (Mg COâ‚‚e/acre to Mg C/pixel)\n",
    "FACTOR = (900 / 4046.86) * (12 / 44) \n",
    "NODATA_ORIGINAL = 65535 # Raster's Nodata value\n",
    "MAX_VALUE = 173 # Maximum clipping value used in the original analysis. Just a error check point.\n",
    "\n",
    "def sum_cleaned_raw(a):\n",
    "    \"\"\"Sum raw pixels (Mg COâ‚‚e/acre) after NoData cleaning and clipping.\"\"\"\n",
    "    \n",
    "    # FIX: Convert to float32 to allow np.nan and perform float calculations\n",
    "    a = a.astype(np.float32) \n",
    "    \n",
    "    # 1. Cleaning\n",
    "    a[a == NODATA_ORIGINAL] = np.nan # Apply NoData\n",
    "    a[a > MAX_VALUE] = np.nan        # Removes inflated values if they exist. \n",
    "    \n",
    "    # 2. Total sum of clean raw values\n",
    "    return np.nansum(a)\n",
    "\n",
    "def count_valid_pixels(a):\n",
    "    \"\"\"Count the number of valid pixels after cleaning.\"\"\"\n",
    "    # Just another checkpoint, had some trouble \"Relying\" on output values. \n",
    "    a = a.astype(np.float32) \n",
    "    a[a == NODATA_ORIGINAL] = np.nan\n",
    "    a[a > MAX_VALUE] = np.nan\n",
    "    return np.nansum(np.isfinite(a))\n",
    "\n",
    "\n",
    "# Reads reprojected polygons\n",
    "gdf = gpd.read_file(filtered_path_reproj) \n",
    "\n",
    "# ---- ZONAL STATISTICS -----\n",
    "print(\" Converting units and running zonal stats...\")\n",
    "\n",
    "# Temporarily suppress rasterstats warnings due to nodata in custom stats. had some\n",
    "# issues with noData values, found this way to prevent it from processing data.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    stats = zonal_stats(\n",
    "        vectors=gdf,\n",
    "        raster=str(clipped_raster), # Use path to ORIGINAL raster\n",
    "        stats=[], \n",
    "        add_stats={'raw_sum_CO2e_acre': sum_cleaned_raw, 'valid_pixels': count_valid_pixels},\n",
    "        geojson_out=False,\n",
    "        nodata=NODATA_ORIGINAL, \n",
    "        all_touched=False\n",
    "    )\n",
    "\n",
    "# Add columns\n",
    "gdf[\"raw_sum_CO2e_acre\"] = [s[\"raw_sum_CO2e_acre\"] for s in stats]\n",
    "gdf[\"valid_pixels\"] = [s[\"valid_pixels\"] for s in stats]\n",
    "\n",
    "# Conversion of units to Mg C\n",
    "print(\"Applying conversion factor (Mg COâ‚‚e/acre to Mg C)...\")\n",
    "gdf[\"total_MgC\"] = gdf[\"raw_sum_CO2e_acre\"] * FACTOR\n",
    "\n",
    "# Removes columns we don't use/want\n",
    "columns_to_drop = [\n",
    "    \"COUNTYNS\", \"GEOIDFQ\", \"LSAD\", \"MTFCC\", \"CSAFP\",\"CBSAFP\",\"CLASSFP\", \n",
    "    \"METDIVFP\", \"FUNCSTAT\", \"ALAND\", \"AWATER\", \"INTPTLAT\", \"INTPTLON\"\n",
    "]\n",
    "\n",
    "# Only drop columns that actually exist (one more check-point for errors)\n",
    "gdf = gdf.drop(columns=[c for c in columns_to_drop if c in gdf.columns])\n",
    "\n",
    "print(f\"ðŸ§¹ Dropped columns: {[c for c in columns_to_drop if c not in gdf.columns]}\")\n",
    "\n",
    "# --- Step 5: Export result ---\n",
    "out_gpkg = OUTPUT / \"carbon_total_by_county.gpkg\"\n",
    "gdf.to_file(out_gpkg, driver=\"GPKG\")\n",
    "\n",
    "print(f\"\\nGeoPackage saved in: {out_gpkg}\")\n",
    "print(\"\\nPreview of results:\")\n",
    "print(gdf[[\"NAME\", \"raw_sum_CO2e_acre\", \"valid_pixels\", \"total_MgC\"]].head())\n",
    "print(f\"\\n Process completed successfully. Total counties processed: {len(gdf)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6457f90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: D:\\Vizzuality_challenge\\data\\output\\carbon_total_by_county.gpkg\n",
      "\n",
      "GeoPackage loaded successfully.\n",
      "Preview:\n",
      "  STATEFP COUNTYFP  GEOID        NAME           NAMELSAD CSAFP  \\\n",
      "0      55      103  55103    Richland    Richland County  None   \n",
      "1      27      051  27051       Grant       Grant County  None   \n",
      "2      55      047  55047  Green Lake  Green Lake County  None   \n",
      "3      55      127  55127    Walworth    Walworth County   376   \n",
      "4      26      045  26045       Eaton       Eaton County   330   \n",
      "\n",
      "   raw_sum_CO2e_acre  valid_pixels     total_MgC  \\\n",
      "0         80253840.0        908127  4.867643e+06   \n",
      "1          4373964.0         67423  2.652944e+05   \n",
      "2         18854288.0        275296  1.143571e+06   \n",
      "3         25412840.0        317963  1.541367e+06   \n",
      "4         35590720.0        440851  2.158687e+06   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((4.48e+05 2.3e+06, 4.48e+05 2.3e+06, ...  \n",
      "1  POLYGON ((-462 2.53e+06, -966 2.53e+06, -971 2...  \n",
      "2  POLYGON ((5.61e+05 2.31e+06, 5.61e+05 2.31e+06...  \n",
      "3  POLYGON ((6.28e+05 2.19e+06, 6.28e+05 2.19e+06...  \n",
      "4  POLYGON ((9.11e+05 2.21e+06, 9.11e+05 2.21e+06...  \n"
     ]
    }
   ],
   "source": [
    "# Upload output to relational database (PostgreSQL + PostGIS)\n",
    "\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "from geoalchemy2 import Geometry\n",
    "from pathlib import Path\n",
    "\n",
    "# Define base project paths\n",
    "OUTPUT = Path(\"data/output\")\n",
    "\n",
    "# Load GeoPackage\n",
    "gpkg = OUTPUT / \"carbon_total_by_county.gpkg\"\n",
    "print(\"Using:\", gpkg.resolve())\n",
    "\n",
    "gdf = gpd.read_file(gpkg)\n",
    "\n",
    "print(\"\\nGeoPackage loaded successfully.\")\n",
    "print(\"Preview:\")\n",
    "print(gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7e2ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQLite database created at: data/output/total_carbon.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Using a SQLite database due to the small size of the project\n",
    "db_path = \"data/output/total_carbon.db\"\n",
    "\n",
    "# Drop geometry if you just want numeric + text fields\n",
    "gdf.drop(columns=\"geometry\").to_sql(\n",
    "    name=\"total_carbon\",\n",
    "    con=sqlite3.connect(db_path),\n",
    "    if_exists=\"replace\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"SQLite database created at:\", db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b7e0094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database:\n",
      " - total_carbon\n",
      "\n",
      "Table structure for 'total_carbon':\n",
      " - STATEFP (TEXT)\n",
      " - COUNTYFP (TEXT)\n",
      " - GEOID (TEXT)\n",
      " - NAME (TEXT)\n",
      " - NAMELSAD (TEXT)\n",
      " - CSAFP (TEXT)\n",
      " - raw_sum_CO2e_acre (REAL)\n",
      " - valid_pixels (INTEGER)\n",
      " - total_MgC (REAL)\n",
      "\n",
      " Data preview:\n",
      "  STATEFP COUNTYFP  GEOID        NAME           NAMELSAD CSAFP  \\\n",
      "0      55      103  55103    Richland    Richland County  None   \n",
      "1      27      051  27051       Grant       Grant County  None   \n",
      "2      55      047  55047  Green Lake  Green Lake County  None   \n",
      "3      55      127  55127    Walworth    Walworth County   376   \n",
      "4      26      045  26045       Eaton       Eaton County   330   \n",
      "\n",
      "   raw_sum_CO2e_acre  valid_pixels     total_MgC  \n",
      "0         80253840.0        908127  4.867643e+06  \n",
      "1          4373964.0         67423  2.652944e+05  \n",
      "2         18854288.0        275296  1.143571e+06  \n",
      "3         25412840.0        317963  1.541367e+06  \n",
      "4         35590720.0        440851  2.158687e+06  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Path to your local or repo database\n",
    "db_path = \"data/output/total_carbon.db\"\n",
    "\n",
    "# Connect to SQLite\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Shows the tables containd in the db. \n",
    "print(\"Tables in database:\")\n",
    "tables = cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "for t in tables:\n",
    "    print(\" -\", t[0])\n",
    "\n",
    "# grabs the column info for the main table\n",
    "print(\"\\nTable structure for 'total_carbon':\")\n",
    "columns = cursor.execute(\"PRAGMA table_info(total_carbon);\").fetchall()\n",
    "for col in columns:\n",
    "    print(f\" - {col[1]} ({col[2]})\")\n",
    "\n",
    "# Previews the first few rows\n",
    "print(\"\\n Data preview:\")\n",
    "df_preview = pd.read_sql(\"SELECT * FROM total_carbon LIMIT 5;\", conn)\n",
    "print(df_preview)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e603135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vizz_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
